FE-595 Assignment 3 (Sentiment Sorting):

This is a README file to be used along with the other files in this git repository to conduct sentiment analysis. The steps mentioned below will help you to understand how these different codes work and what their functions are:

1. "Assignment3_1.py" will merge different types of files like .csv and .txt into one large csv file and export it to the working directory.
2. "Assignment3_2.py" will look at the exported csv from the previous step and conduct sentiment analysis on the "Purpose" column. Based on the Compound score, we will determine the maximum and minimum and print those companies. 
3. "Assignment3_3.py" is used to find the top ten most used words in the purpose column. It is possible to use the nltk library to create tokens but I wanted specific words like "info-mediaries" to be counted as a single entity.

Let me know if you need any additional information!
Link to git repository: https://github.com/apadman2/FE-595-Assignment-3-Sentiment-sorting-/tree/main 